"""
ü§ñ Interpretador com HuggingFace Zero-Shot Classification
Integra√ß√£o com o interpretador existente para melhorar detec√ß√£o de inten√ß√µes
"""

import os
from typing import Dict, Optional, List
from functools import lru_cache

try:
    from transformers import pipeline
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    print("‚ö†Ô∏è Transformers n√£o instalado. Instale com: pip install transformers torch")


class InterpretadorComTransformers:
    """
    Interpretador melhorado com HuggingFace Transformers
    Combina classifica√ß√£o zero-shot com seu sistema existente
    """
    
    def __init__(self, usar_transformers=True):
        self.usar_transformers = usar_transformers and TRANSFORMERS_AVAILABLE
        self.classifier = None
        
        # Inten√ß√µes que seu sistema reconhece
        self.intencoes = [
            'agenda',
            'tarefa', 
            'lembrete',
            'financeiro',
            'email',
            'sistema',
            'conversa'
        ]
        
        # Mapeamento de sin√¥nimos para inten√ß√µes
        self.sinonimos_intencao = {
            'agenda': ['evento', 'compromisso', 'reuni√£o', 'encontro', 'marca√ß√£o'],
            'tarefa': ['afazer', 'trabalho', 'dever', 'responsabilidade'],
            'lembrete': ['aviso', 'alerta', 'notifica√ß√£o', 'alarme'],
            'financeiro': ['gasto', 'despesa', 'receita', 'dinheiro', 'custa'],
            'email': ['mensagem', 'correspond√™ncia', 'mail'],
            'conversa': ['bate-papo', 'conversa', 'pergunta'],
            'sistema': ['ajuda', 'status', 'comando']
        }
        
        if self.usar_transformers:
            self._carregar_modelo()
    
    def _carregar_modelo(self):
        """Carrega modelo HuggingFace de forma lazy"""
        try:
            print("üì¶ Carregando modelo HuggingFace (primeira vez pode demorar)...")
            self.classifier = pipeline(
                "zero-shot-classification",
                model="facebook/bart-large-mnli",
                device=self._get_device()
            )
            print("‚úÖ Modelo carregado com sucesso!")
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao carregar modelo: {e}")
            self.usar_transformers = False
    
    @staticmethod
    def _get_device():
        """Detecta se CUDA est√° dispon√≠vel"""
        try:
            import torch
            return 0 if torch.cuda.is_available() else -1
        except:
            return -1  # CPU
    
    @lru_cache(maxsize=1000)
    def interpretar_com_transformers(self, mensagem: str) -> Dict:
        """
        Interpreta mensagem usando zero-shot classification
        
        Args:
            mensagem: Texto a interpretar
            
        Returns:
            Dicion√°rio com inten√ß√£o e confian√ßa
        """
        if not self.usar_transformers or self.classifier is None:
            return self._resultado_vazio(mensagem)
        
        try:
            resultado = self.classifier(
                mensagem,
                self.intencoes,
                multi_class=False,
                hypothesis_template="Este texto √© sobre {}."
            )
            
            return {
                'intencao': resultado['labels'][0],
                'confianca': float(resultado['scores'][0]),
                'alternativas': list(zip(resultado['labels'], resultado['scores'])),
                'metodo': 'transformers',
                'mensagem': mensagem
            }
        except Exception as e:
            print(f"‚ùå Erro ao interpretar: {e}")
            return self._resultado_vazio(mensagem)
    
    def _resultado_vazio(self, mensagem: str) -> Dict:
        """Retorna resultado vazio quando classifier n√£o est√° dispon√≠vel"""
        return {
            'intencao': None,
            'confianca': 0.0,
            'alternativas': [],
            'metodo': 'erro',
            'mensagem': mensagem
        }
    
    def combinar_com_interpretador_local(self, 
                                        mensagem: str,
                                        resultado_local: Dict) -> Dict:
        """
        Combina resultado local com resultado Transformers
        Usa confian√ßa combinada para decis√£o final
        
        Args:
            mensagem: Mensagem original
            resultado_local: Resultado do interpretador local
            
        Returns:
            Resultado combinado com melhor confian√ßa
        """
        if not self.usar_transformers:
            return resultado_local
        
        # Obter resultado do Transformers
        resultado_tf = self.interpretar_com_transformers(mensagem)
        
        # Se ambos concordam e confian√ßa √© alta, usar
        if (resultado_local.get('intencao') == resultado_tf['intencao'] and
            resultado_local.get('confianca', 0) > 0.7 and
            resultado_tf['confianca'] > 0.7):
            
            # Combinar confian√ßasmedia_confianca = (resultado_local.get('confianca', 0.5) + resultado_tf['confianca']) / 2
            resultado_local['confianca'] = media_confianca
            resultado_local['metodo'] = 'combinado'
            return resultado_local
        
        # Se Transformers tem confian√ßa muito alta, usar
        if resultado_tf['confianca'] > 0.85:
            return resultado_tf
        
        # Caso contr√°rio, usar resultado local
        return resultado_local
    
    def obter_intenao_corrigida(self, 
                               mensagem: str,
                               intenao_usuario: Optional[str] = None) -> str:
        """
        Obt√©m inten√ß√£o corrigida com feedback do usu√°rio
        
        Args:
            mensagem: Mensagem interpretada
            intenao_usuario: Inten√ß√£o corrigida pelo usu√°rio
            
        Returns:
            Inten√ß√£o final (corrigida ou original)
        """
        if intenao_usuario in self.intencoes:
            # Guardar feedback para futuro treinamento
            self._guardar_feedback(mensagem, intenao_usuario)
            return intenao_usuario
        
        return self.interpretar_com_transformers(mensagem)['intencao']
    
    def _guardar_feedback(self, mensagem: str, intenacao_correta: str):
        """Guarda feedback para futuro fine-tuning"""
        # Implementar persist√™ncia em arquivo ou BD
        feedback_file = 'data/feedback_interpretador.jsonl'
        
        import json
        from datetime import datetime
        
        feedback = {
            'timestamp': datetime.now().isoformat(),
            'mensagem': mensagem,
            'intenacao': intenacao_correta
        }
        
        try:
            with open(feedback_file, 'a', encoding='utf-8') as f:
                f.write(json.dumps(feedback, ensure_ascii=False) + '\n')
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao guardar feedback: {e}")
    
    def treinar_modelo_customizado(self, exemplos: List[tuple]):
        """
        Fine-tuning com seus dados customizados
        
        Args:
            exemplos: Lista de (mensagem, inten√ß√£o)
            
        Exemplo:
            exemplos = [
                ("Tenho reuni√£o amanh√£", "agenda"),
                ("Preciso comprar leite", "tarefa"),
                ("Me lembra em 30 minutos", "lembrete")
            ]
        """
        try:
            from simpletransformers.classification import ClassificationModel
            
            print("üîÑ Iniciando fine-tuning...")
            
            # Preparar dados
            train_data = [
                [msg, self.intencoes.index(intent)]
                for msg, intent in exemplos
            ]
            
            # Criar modelo customizado
            model = ClassificationModel(
                'bert',
                'bert-base-multilingual-cased',
                num_labels=len(self.intencoes),
                args={'num_train_epochs': 3}
            )
            
            # Treinar
            model.train_model(train_data)
            
            print("‚úÖ Modelo treinado com sucesso!")
            
        except ImportError:
            print("‚ö†Ô∏è SimpleTransformers n√£o instalado.")
            print("Instale com: pip install simpletransformers")


# ============ EXEMPLOS DE USO ============

def exemplo_basico():
    """Exemplo b√°sico de uso"""
    print("\n=== Exemplo 1: Uso B√°sico ===\n")
    
    interpretador = InterpretadorComTransformers()
    
    mensagens = [
        "Tenho reuni√£o amanh√£ √†s 14h",
        "Preciso comprar leite no mercado",
        "Me lembra em 30 minutos",
        "Gastei 50 reais no almo√ßo",
        "Oi, tudo bem?",
        "Buscar email de Jo√£o"
    ]
    
    for msg in mensagens:
        resultado = interpretador.interpretar_com_transformers(msg)
        print(f"üìù '{msg}'")
        print(f"   ‚Üí Inten√ß√£o: {resultado['intencao']}")
        print(f"   ‚Üí Confian√ßa: {resultado['confianca']:.2%}")
        print()


def exemplo_combinado():
    """Exemplo combinando com interpretador local"""
    print("\n=== Exemplo 2: Combinado (Local + Transformers) ===\n")
    
    interpretador = InterpretadorComTransformers()
    
    # Simular resultado local
    resultado_local = {
        'intencao': 'agenda',
        'confianca': 0.80,
        'parametros': {'data': '2024-12-09'}
    }
    
    mensagem = "Tenho reuni√£o amanh√£"
    resultado_combinado = interpretador.combinar_com_interpretador_local(
        mensagem, 
        resultado_local
    )
    
    print(f"Mensagem: '{mensagem}'")
    print(f"Resultado Combinado:")
    print(f"  - Inten√ß√£o: {resultado_combinado['intencao']}")
    print(f"  - Confian√ßa: {resultado_combinado['confianca']:.2%}")
    print(f"  - M√©todo: {resultado_combinado['metodo']}")


def exemplo_feedback():
    """Exemplo com feedback do usu√°rio"""
    print("\n=== Exemplo 3: Com Feedback ===\n")
    
    interpretador = InterpretadorComTransformers()
    
    mensagem = "Me avisa em 1 hora"
    resultado = interpretador.interpretar_com_transformers(mensagem)
    
    print(f"Mensagem: '{mensagem}'")
    print(f"Interpreta√ß√£o: {resultado['intencao']} ({resultado['confianca']:.2%})")
    
    # Usu√°rio corrige
    intenacao_corrigida = interpretador.obter_intenao_corrigida(
        mensagem,
        intenacao_usuario='lembrete'
    )
    
    print(f"Inten√ß√£o Corrigida: {intenacao_corrigida}")
    print("‚úÖ Feedback guardado para futuro treinamento")


def exemplo_multiplas_opcoes():
    """Exemplo com m√∫ltiplas op√ß√µes de classifica√ß√£o"""
    print("\n=== Exemplo 4: M√∫ltiplas Op√ß√µes ===\n")
    
    interpretador = InterpretadorComTransformers()
    
    mensagem = "Preciso lembrar de pagar a conta"
    resultado = interpretador.interpretar_com_transformers(mensagem)
    
    print(f"Mensagem: '{mensagem}'")
    print(f"\nOp√ß√µes de Classifica√ß√£o:")
    for i, (intenacao, score) in enumerate(resultado['alternativas'], 1):
        print(f"  {i}. {intenacao}: {score:.2%}")


if __name__ == '__main__':
    print("üöÄ Exemplos de Interpretador com Transformers\n")
    
    try:
        exemplo_basico()
        exemplo_combinado()
        exemplo_feedback()
        exemplo_multiplas_opcoes()
        
        print("\n‚úÖ Todos os exemplos executados com sucesso!")
        
    except Exception as e:
        print(f"\n‚ùå Erro durante execu√ß√£o: {e}")
        print("\nCertifique-se de instalar as depend√™ncias:")
        print("pip install transformers torch")

